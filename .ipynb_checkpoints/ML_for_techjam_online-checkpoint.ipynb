{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv('IsusV3.csv', delimiter = ',').reset_index(drop=True)\n",
    "data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\n",
    "# data\n",
    "# dataIsusV2forTrain\n",
    "train = pd.read_csv('train.csv', delimiter = ',').reset_index(drop=True)\n",
    "test = pd.read_csv('test.csv', delimiter = ',').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8576, 136) (2144, 136)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "park = pd.read_csv('park_1.csv', delimiter = ',').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "park['test'] = \"\"\n",
    "# f1_score(y_train, y_pre_2, average='binary')\n",
    "park[park['Prediction'] >= 0.5]['test'] = 1\n",
    "park[park['Prediction'] < 0.5]['test'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.303171</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.239810</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.375598</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.181755</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.302520</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.735293</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.455887</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.278021</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.239720</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.327504</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.260102</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.495029</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.232135</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.242630</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.204714</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.140909</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.113586</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.109751</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.082024</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.123483</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.105294</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.089132</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.069750</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.167424</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.099446</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>2114</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2115</td>\n",
       "      <td>0.054676</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>2116</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>2117</td>\n",
       "      <td>0.032269</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>2118</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>2119</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>2120</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>2121</td>\n",
       "      <td>0.047482</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2122</td>\n",
       "      <td>0.034405</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>2123</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>2124</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2125</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2126</td>\n",
       "      <td>0.048639</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2127</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2128</td>\n",
       "      <td>0.035833</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2129</td>\n",
       "      <td>0.061618</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>2130</td>\n",
       "      <td>0.046002</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>2131</td>\n",
       "      <td>0.053455</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>2132</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>2133</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2134</td>\n",
       "      <td>0.038275</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2135</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2136</td>\n",
       "      <td>0.025052</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2137</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>2138</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2139</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2140</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>2141</td>\n",
       "      <td>0.031399</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>2142</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>2143</td>\n",
       "      <td>0.057303</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  Prediction  Actual test\n",
       "0          0    0.303171       1     \n",
       "1          1    0.239810       0     \n",
       "2          2    0.375598       0     \n",
       "3          3    0.181755       1     \n",
       "4          4    0.209790       0     \n",
       "5          5    0.751699       1     \n",
       "6          6    0.302520       0     \n",
       "7          7    0.735293       1     \n",
       "8          8    0.254448       0     \n",
       "9          9    0.455887       0     \n",
       "10        10    0.278021       0     \n",
       "11        11    0.239720       0     \n",
       "12        12    0.327504       0     \n",
       "13        13    0.260102       0     \n",
       "14        14    0.495029       1     \n",
       "15        15    0.232135       0     \n",
       "16        16    0.242630       1     \n",
       "17        17    0.204714       0     \n",
       "18        18    0.140909       0     \n",
       "19        19    0.069184       0     \n",
       "20        20    0.113586       0     \n",
       "21        21    0.109751       0     \n",
       "22        22    0.082024       0     \n",
       "23        23    0.123483       0     \n",
       "24        24    0.105294       0     \n",
       "25        25    0.089132       0     \n",
       "26        26    0.069750       0     \n",
       "27        27    0.167424       0     \n",
       "28        28    0.115754       1     \n",
       "29        29    0.099446       1     \n",
       "...      ...         ...     ...  ...\n",
       "2114    2114    0.038938       0     \n",
       "2115    2115    0.054676       0     \n",
       "2116    2116    0.041165       0     \n",
       "2117    2117    0.032269       0     \n",
       "2118    2118    0.037862       0     \n",
       "2119    2119    0.034359       0     \n",
       "2120    2120    0.025359       0     \n",
       "2121    2121    0.047482       0     \n",
       "2122    2122    0.034405       0     \n",
       "2123    2123    0.035412       0     \n",
       "2124    2124    0.047975       0     \n",
       "2125    2125    0.044281       0     \n",
       "2126    2126    0.048639       0     \n",
       "2127    2127    0.045504       0     \n",
       "2128    2128    0.035833       0     \n",
       "2129    2129    0.061618       0     \n",
       "2130    2130    0.046002       1     \n",
       "2131    2131    0.053455       0     \n",
       "2132    2132    0.048545       0     \n",
       "2133    2133    0.030954       0     \n",
       "2134    2134    0.038275       0     \n",
       "2135    2135    0.036724       0     \n",
       "2136    2136    0.025052       0     \n",
       "2137    2137    0.051369       0     \n",
       "2138    2138    0.035412       0     \n",
       "2139    2139    0.037356       0     \n",
       "2140    2140    0.037380       0     \n",
       "2141    2141    0.031399       0     \n",
       "2142    2142    0.043251       0     \n",
       "2143    2143    0.057303       1     \n",
       "\n",
       "[2144 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(['Target'], axis=1).fillna(0)\n",
    "# data1 = data1.values\n",
    "y = data[['Target']].values\n",
    "data1.shape\n",
    "# y\n",
    "x_train_ = train.drop(['Target'], axis=1).fillna(0)\n",
    "y_train = train[['Target']].values\n",
    "\n",
    "x_test_ = test.drop(['Target'], axis=1).fillna(0)\n",
    "y_test = test[['Target']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.to_dict('records')\n",
    "x_train = x_train_.to_dict('records')\n",
    "# y_train = y_train_.to_dict('records')\n",
    "\n",
    "x_test = x_test_.to_dict('records')\n",
    "# y_test = y_test_.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10720, 166)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "vec = DictVectorizer()\n",
    "x = vec.fit_transform(x).toarray()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166,)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vec.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vec.fit_transform(x_train).toarray()\n",
    "x_test = vec.fit_transform(x_test).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8576, 172) (2144, 172)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-63576.91703737   2782.9191994    -541.87336475 ...   -670.28859429\n",
      "   -2721.05809825   -300.05856659]\n",
      " [-43608.74402376   6030.78636414   -475.28138398 ...   3102.03921887\n",
      "   -5801.25723623  -1509.79978176]\n",
      " [ 24843.06453472  49860.004107      845.43314859 ...  45259.22783883\n",
      "   50447.20659134  70402.38847607]\n",
      " ...\n",
      " [-50579.20829197   3370.12739174  -5192.15261753 ...  -4611.02476676\n",
      "   -1598.41554993   1610.03188155]\n",
      " [-65180.65762811   5596.07592944  -1728.6282631  ...  -3374.42772674\n",
      "   -1923.03149312    817.89095082]\n",
      " [-64213.8695753    2419.93884533   -377.67966346 ...  -2164.28930306\n",
      "     155.40102658   2698.02419889]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] (10720, 27) (10720, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 27\n",
    "pca = PCA(n_components=n_components, svd_solver='full',random_state=42)\n",
    "pca.fit(x)\n",
    "x = pca.fit_transform(x)\n",
    "\n",
    "\n",
    "print(x,y,x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10720, 27) (10720, 1)\n",
      "(8576, 27) (8576, 1) (2144, 27) (2144, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.fit_transform(x_test)\n",
    "print(x.shape,y.shape)\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_test\n",
    "y_val = y_test\n",
    "# x_sm, y_sm = x_train , y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 166) (8000, 1) (2720, 166) (2720, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x[:8000][:]\n",
    "y_train = y[:8000][:]\n",
    "# x_train2 = x[6000:8000][:]\n",
    "# y_train2 = y[6000:8000][:]\n",
    "x_val = x[8000:][:]\n",
    "y_val = y[8000:][:]\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16142, 27) (16142,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "# smote = SMOTE(ratio='minority')\n",
    "# sm = SMOTE(random_state=42)\n",
    "sm = ADASYN(random_state=42)\n",
    "# x_sm, y_sm = sm.fit_sample(x_train, y_train)\n",
    "# x_sm, y_sm = x_train, y_train\n",
    "x_sm, y_sm = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "print(x_sm.shape,y_sm.shape)\n",
    "\n",
    "\n",
    "# x_sm2, y_sm2 = sm.fit_sample(x_train2, y_train2)\n",
    "# print(x_sm2.shape,y_sm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 172)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_sm.shape\n",
    "# x_sm = x_sm[:,np.array([9,10,11,136,148,154,156,158,159])]\n",
    "# x_sm.shape\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=20, svd_solver='full',random_state=42)\n",
    "# x_sm = pca.fit_transform(x_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 20)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "n_jobs = -1\n",
    "n_iter = 50\n",
    "n_iter_nt = 3\n",
    "n_components = 27\n",
    "cv = 5\n",
    "seed=42\n",
    "# n_features= x_sm.shape[1]\n",
    "n_features= n_components\n",
    "is_pca = False\n",
    "# is_pca = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15096, 20)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=20, svd_solver='full',random_state=42)\n",
    "pca.fit(x_sm)\n",
    "fitt = pca.fit_transform(x_sm)\n",
    "fitt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to NMF (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-339-3487ab773960>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'both'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             shuffle=self.shuffle)\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m         self.reconstruction_err_ = _beta_divergence(X, W, H, self.beta_loss,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m     \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NMF (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m     \u001b[0mbeta_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_string_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to NMF (input X)"
     ]
    }
   ],
   "source": [
    "nmf.fit_transform(x_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=5, random_state=42,\n",
       "  svd_solver='full', tol=0.0, whiten=False)), ('lgb', RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_b...obs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'reduce_dim': [PCA(copy=True, iterated_power=7, n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)], 'reduce_dim__n_components': [2, 4, 8, 10, 14, 16, 18, 20]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA ,NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "# nmf = NMF(n_components=5, init='random', random_state=42)\n",
    "\n",
    "# C_OPTIONS = [1, 10, 100, 1000]\n",
    "N_FEATURES_OPTIONS = [5 ,10 , 15, 20, 25 , 40 ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "#         'classify__C': C_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "pca = PCA(n_components=5, svd_solver='full',random_state=42)\n",
    "estimators = [('reduce_dim',pca ), ('lgb', xgb)]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09929078014184398 0.845878136200717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# v = DictVectorizer(sparse=False)\n",
    "# d = [{'height': 1, 'length': 0, 'width': 1},{'height': 2, 'length': 1, 'width': 0},{'height': 1, 'length': 3, 'width': 2}]\n",
    "# v.fit_transform(d)\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score\n",
    "model = grid\n",
    "model.fit(x_sm, y_sm)\n",
    "y_pre = model.predict(x_val)\n",
    "f1_1  = f1_score(y_val, y_pre, average='binary')\n",
    "y_pre_2 = model.predict(x_train)\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1_1,f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduce_dim': PCA(copy=True, iterated_power=7, n_components=18, random_state=None,\n",
       "   svd_solver='auto', tol=0.0, whiten=False), 'reduce_dim__n_components': 18}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.best_params_.named_steps['lgb'].best_params_\n",
    "# model.best_params_.named_steps['reduce_dim']\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66653831 0.30894309] 0.0420353982300885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48774070143473863"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "y_pre.sum()\n",
    "recall = recall_score(y_val, y_pre,pos_label=1, average=None)\n",
    "prec = precision_score(y_val, y_pre,pos_label=1, average='binary')\n",
    "\n",
    "print(recall,prec)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pre, pos_label=1)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA ,NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "N_FEATURES_OPTIONS = [5 ,10 , 15, 20, 25 , 40 ]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "#         'classify__C': C_OPTIONS\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(nthreads=-1,tree_method='exact')\n",
    "\n",
    "objective = 'binary:logistic'\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'objective': [objective],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "xgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', xgb)]\n",
    "    xgb = Pipeline(estimators)\n",
    "    xgb = GridSearchCV(xgb, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', log)]\n",
    "    log = Pipeline(estimators)\n",
    "    log = GridSearchCV(log, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "# Parameter for KNeighborsClassifier\n",
    "params = {\n",
    "    \"n_neighbors\": st.randint(2, 50),\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    \"leaf_size\": st.randint(10, 30),\n",
    "    \"p\": st.randint(1, 2),\n",
    "}\n",
    "knn = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', knn)]\n",
    "    knn = Pipeline(estimators)\n",
    "#     knn = GridSearchCV(knn, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', rnf)]\n",
    "    rnf = Pipeline(estimators)\n",
    "    rnf = GridSearchCV(rnf, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ExtraTreesClassifier()\n",
    "# \n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', ext)]\n",
    "    ext = Pipeline(estimators)\n",
    "    ext = GridSearchCV(ext, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = AdaBoostClassifier()\n",
    "\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "    'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', ada)]\n",
    "    ada = Pipeline(estimators)\n",
    "    ada = GridSearchCV(ada, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC()\n",
    "\n",
    "# Parameter for SVC\n",
    "params = {  \n",
    "    'C':[0.001, 0.01, 0.1, 1, 10], \n",
    "    'degree': st.randint(1, 10),\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True],\n",
    "    'tol': [1e-3],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "svc = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', svc)]\n",
    "    svc = Pipeline(estimators)\n",
    "#     svc = GridSearchCV(svc, cv=5, n_jobs=-1, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for LGBMClassifier\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "estimator = LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40,30],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "params = {  \n",
    "            \"boosting_type\": [\"gbdt\",\"rf\",\"dart\"],\n",
    "            \"colsample_bytree\": st.beta(10, 1),\n",
    "            \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "            \"max_depth\": st.randint(3, 30),\n",
    "            \"min_child_weight\": st.expon(0, 50),\n",
    "            \"n_estimators\": st.randint(3, 40),\n",
    "            \"num_leaves\": st.randint(30, 50),\n",
    "            'objective': ['binary'],\n",
    "            \"subsample\": st.beta(10, 1),\n",
    "            \"seed\": [seed],\n",
    "        }\n",
    "\n",
    "lgb = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs)\n",
    "if(is_pca):\n",
    "    print('asas')\n",
    "    estimators = [('reduce_dim', PCA(n_components=n_components, svd_solver='full')), ('clf', lgb)]\n",
    "    lgb = Pipeline(estimators)\n",
    "    lgb = GridSearchCV(lgb, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "# lgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16093, 172)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002354E3F30B8>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002354E3F3240>, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': [42]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(x_sm,y_sm)\n",
    "\n",
    "xgb.fit(x_sm,y_sm)\n",
    "log.fit(x_sm,y_sm)\n",
    "knn.fit(x_sm,y_sm)\n",
    "rnf.fit(x_sm,y_sm)\n",
    "ext.fit(x_sm,y_sm)\n",
    "ada.fit(x_sm,y_sm)\n",
    "\n",
    "# svc.fit(x_sm,y_sm) tree_method\n",
    "\n",
    "# y_pre_2 = xgb.predict(x_train)\n",
    "# f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "# joblib.dump(xgb, 'xgb.pkl') \n",
    "# joblib.dump(log, 'log.pkl') \n",
    "# joblib.dump(knn, 'knn.pkl') \n",
    "# joblib.dump(rnf, 'rnf.pkl') \n",
    "# joblib.dump(ext, 'ext.pkl') \n",
    "# joblib.dump(ada, 'ada.pkl') \n",
    "# joblib.dump(svc, 'svc.pkl') \n",
    "# vote2 = joblib.load('vote.pkl') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb.pkl']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb, 'xgb.pkl') \n",
    "joblib.dump(log, 'log.pkl') \n",
    "joblib.dump(knn, 'knn.pkl') \n",
    "joblib.dump(rnf, 'rnf.pkl') \n",
    "joblib.dump(ext, 'ext.pkl') \n",
    "joblib.dump(ada, 'ada.pkl') \n",
    "joblib.dump(lgb, 'lgb.pkl') \n",
    "# joblib.dump(svc, 'svc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params1 = xgb.best_params_\n",
    "best_params2 = log.best_params_\n",
    "best_params3 = knn.best_params_\n",
    "best_params4 = rnf.best_params_\n",
    "best_params5 = ext.best_params_\n",
    "best_params6 = ada.best_params_\n",
    "best_params7 = lgb.best_params_\n",
    "# best_params8 = svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.860316010329701,\n",
       " 'gamma': 0.15929001125634445,\n",
       " 'learning_rate': 0.30743808141316603,\n",
       " 'max_depth': 13,\n",
       " 'min_child_weight': 5.163432466194721,\n",
       " 'n_estimators': 27,\n",
       " 'objective': 'binary:logistic',\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 42,\n",
       " 'subsample': 0.9560990543756147}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = joblib.load('xgb.pkl')\n",
    "# log = joblib.load('log.pkl') \n",
    "# knn = joblib.load('knn.pkl') \n",
    "# rnf = joblib.load('rnf.pkl') \n",
    "# ext = joblib.load('ext.pkl') \n",
    "# ada = joblib.load('ada.pkl') \n",
    "# svc = joblib.load('svc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2720, 166)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_val = x_val[:,np.array([9,10,11,136,148,154,156,158,159])]\n",
    "# x_train = x_train[:,np.array([9,10,11,136,148,154,156,158,159])]\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09119999999999999 0.9503407984420642 xgb\n",
      "0.11443779108449767 0.12941176470588234 log\n",
      "0.07243460764587524 1.0 knn\n",
      "0.074719800747198 0.961271102284012 rnf\n",
      "0.07942238267148015 0.9407265774378585 ext\n",
      "0.09990749306197964 0.18773234200743494 ada\n",
      "0.09991673605328893 0.19865771812080538 lgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score\n",
    "y_pre = xgb.predict(x_val)\n",
    "y_pre_2 = xgb.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'xgb')\n",
    "y_pre = log.predict(x_val)\n",
    "y_pre_2 = log.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'log')\n",
    "y_pre = knn.predict(x_val)\n",
    "y_pre_2 = knn.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'knn')\n",
    "y_pre = rnf.predict(x_val)\n",
    "y_pre_2 = rnf.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'rnf')\n",
    "y_pre = ext.predict(x_val)\n",
    "y_pre_2 = ext.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ext')\n",
    "y_pre = ada.predict(x_val)\n",
    "y_pre_2 = ada.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ada')\n",
    "y_pre = lgb.predict(x_val)\n",
    "y_pre_2 = lgb.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'lgb')\n",
    "# y_pre = svc.predict(x_val)\n",
    "# y_pre_2 = svc.predict(x_train)\n",
    "# f1  = f1_score(y_val, y_pre, average='binary')\n",
    "# f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "# print(f1,f1_2,'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00834905, 0.        , 0.        , 0.        , 0.00920586,\n",
       "       0.01012321, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01370775, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00632684, 0.        ,\n",
       "       0.        , 0.04433919, 0.00605415, 0.        , 0.        ,\n",
       "       0.02054843, 0.        , 0.03315179, 0.08930309, 0.02958396,\n",
       "       0.08670702, 0.05670399, 0.01239347, 0.02800984, 0.        ,\n",
       "       0.01946984, 0.01227604, 0.02419606, 0.        , 0.        ,\n",
       "       0.04129673, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02704987, 0.        , 0.01335804, 0.        , 0.        ,\n",
       "       0.02205143, 0.        , 0.        , 0.        , 0.01327537,\n",
       "       0.03839346, 0.        , 0.0161746 , 0.        , 0.        ,\n",
       "       0.01438881, 0.        , 0.01830282, 0.02040816, 0.0214357 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01855491, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00870003, 0.        , 0.        , 0.        , 0.00995637,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01249901, 0.03147816, 0.01661855,\n",
       "       0.        , 0.0213823 , 0.00669973, 0.        , 0.01074305,\n",
       "       0.        , 0.        , 0.00908235, 0.0111856 , 0.01626681,\n",
       "       0.        , 0.        , 0.        , 0.01153407, 0.        ,\n",
       "       0.03818805, 0.        , 0.        , 0.        , 0.0032188 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01730762, 0.        ])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = log.best_estimator_.coef_\n",
    "a = ada.best_estimator_.feature_importances_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5   9  10  31  38  41  42  45  47  48  49  50  51  52  53  55  56  57\n",
      "  60  65  67  70  74  75  77  80  82  83  84 120 125 129 142 143 144 146\n",
      " 147 149 152 153 154 158 160 164 170] [  9  10  11 136 148 154 156 158 159]\n"
     ]
    }
   ],
   "source": [
    "# print(np.argwhere(a>0.01),np.argwhere(a<-0.01))\n",
    "# print(np.argwhere(a!=0))\n",
    "b = np.argwhere(a!=0)\n",
    "# np.reshape(b,(b.shape[]))\n",
    "b = b.ravel()\n",
    "print(b,np.array([9,10,11,136,148,154,156,158,159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   9]\n",
      " [  0  10]\n",
      " [  0  11]\n",
      " [  0 136]\n",
      " [  0 148]\n",
      " [  0 156]\n",
      " [  0 158]\n",
      " [  0 159]] [[  0 154]]\n"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(a>0.01),np.argwhere(a<-0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 45)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm2 = x_sm[:,np.array(b)]\n",
    "x_sm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = xgb.predict_proba(x_sm)\n",
    "re2 = log.predict_proba(x_sm)\n",
    "re3 = knn.predict_proba(x_sm)\n",
    "re4 = rnf.predict_proba(x_sm)\n",
    "re5 = ext.predict_proba(x_sm)\n",
    "re6 = ada.predict_proba(x_sm)\n",
    "re7 = lgb.predict_proba(x_sm)\n",
    "\n",
    "# re8 = svc.predict_proba(x_sm)\n",
    "\n",
    "mo1 = 1\n",
    "mo2 = 1\n",
    "mo3 = 1\n",
    "mo4 = 1\n",
    "mo5 = 1\n",
    "mo6 = 1\n",
    "mo7 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo1 = 0\n",
    "mo2 = 1\n",
    "mo3 = 0\n",
    "mo4 = 0\n",
    "mo5 = 0\n",
    "mo6 = 1\n",
    "mo7 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = xgb.predict_proba(x_val)\n",
    "# test[:,0]\n",
    "\n",
    "\n",
    "re_1 = re1[:,0]\n",
    "re_2 = re2[:,0]\n",
    "re_3 = re3[:,0]\n",
    "re_4 = re4[:,0]\n",
    "re_5 = re5[:,0]\n",
    "re_6 = re6[:,0]\n",
    "re_7 = re7[:,0]\n",
    "\n",
    "\n",
    "re_1 = np.reshape(re_1, (re_1.shape[0],1))\n",
    "re_2 = np.reshape(re_2, (re_2.shape[0],1))\n",
    "re_3 = np.reshape(re_3, (re_3.shape[0],1))\n",
    "re_4 = np.reshape(re_4, (re_4.shape[0],1))\n",
    "re_5 = np.reshape(re_5, (re_5.shape[0],1))\n",
    "re_6 = np.reshape(re_6, (re_6.shape[0],1))\n",
    "re_7 = np.reshape(re_7, (re_7.shape[0],1))\n",
    "# xx = x_sm\n",
    "if(mo1 == 1):\n",
    "    xx = np.concatenate((xx, re_1), axis=1)\n",
    "if(mo2 == 1):\n",
    "    xx = np.concatenate((xx, re_2), axis=1)\n",
    "if(mo3 == 1):\n",
    "    xx = np.concatenate((xx, re_3), axis=1)\n",
    "if(mo4 == 1):\n",
    "    xx = np.concatenate((xx, re_4), axis=1)\n",
    "if(mo5 == 1):\n",
    "    xx = np.concatenate((xx, re_5), axis=1)\n",
    "if(mo6 == 1):\n",
    "    xx = np.concatenate((xx, re_6), axis=1)\n",
    "if(mo7 == 1):\n",
    "    xx = np.concatenate((xx, re_7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16156, 23)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "n_iter = 30\n",
    "cv = 5\n",
    "seed=42\n",
    "# n_features=xx.shape[1]\n",
    "n_features= xx.shape[1]\n",
    "\n",
    "estimator = XGBClassifier(nthreads=-1)\n",
    "objective = 'binary:logistic'\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'objective': [objective],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "xgb2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = ExtraTreesClassifier()\n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = AdaBoostClassifier()\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "    'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter)\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "estimator = LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "lgb2 = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_bin=512,\n",
       "        max_depth=-1, min_child_samples=5, min_child_weight=1,\n",
       "        min_split_gain=0.5, n_estimators=100, n_jobs=3, num_leaves=31,\n",
       "        objective='binary', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, scale_pos_weight=1, silent=True, subsample=1,\n",
       "        subsample_for_bin=200, subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.005], 'n_estimators': [40], 'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'random_state': [42, 502], 'colsample_bytree': [0.65, 0.66], 'subsample': [0.7, 0.75], 'reg_alpha': [1, 1.2], 'reg_lambda': [1, 1.2, 1.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2.fit(xx,y_sm)\n",
    "log2.fit(xx,y_sm)\n",
    "rnf2.fit(xx,y_sm)\n",
    "ext2.fit(xx,y_sm)\n",
    "ada2.fit(xx,y_sm)\n",
    "lgb2.fit(xx,y_sm)\n",
    "\n",
    "\n",
    "# joblib.dump(xgb2, 'xgb2.pkl') \n",
    "# joblib.dump(log2, 'log2.pkl') \n",
    "# joblib.dump(rnf2, 'rnf2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 179)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09532538955087076 0.18214771182600817 vote2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# vote_list = [('xgb2', xgb2), ('log2', log2), ('rnf2', rnf2), ('ext2', ext2)]\n",
    "vote_list = [ ('log2', log2), ('ada2', ada2), ('lgb2', lgb2)]\n",
    "vote2 = VotingClassifier(estimators=vote_list, voting='hard')\n",
    "vote2.fit(xx, y_sm)\n",
    "# vote2.fit(xx_val, y_val)\n",
    "# joblib.dump(vote2, 'vote2.pkl') \n",
    "# vote2.feature_importances_\n",
    "y_pre = vote2.predict(xx_val)\n",
    "y_pre_2 = vote2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15096, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_val.shape\n",
    "re_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx_val = x_val[:,np.array(b)]\n",
    "# xx_train = x_train[:,np.array(b)]\n",
    "\n",
    "xx_val = x_val\n",
    "xx_train = x_train\n",
    "\n",
    "# re1 = xgb2.predict_proba(x_sm)\n",
    "# re2 = log.predict_proba(x_sm)\n",
    "# re3 = knn.predict_proba(x_sm)\n",
    "\n",
    "re11 = xgb.predict_proba(x_val)\n",
    "re12 = log.predict_proba(x_val)\n",
    "re13 = knn.predict_proba(x_val)\n",
    "re14 = rnf.predict_proba(x_val)\n",
    "re15 = ext.predict_proba(x_val)\n",
    "re16 = ada.predict_proba(x_val)\n",
    "re17 = lgb.predict_proba(x_val)\n",
    "\n",
    "re_11 = re11[:,0]\n",
    "re_12 = re12[:,0]\n",
    "re_13 = re13[:,0]\n",
    "re_14 = re14[:,0]\n",
    "re_15 = re15[:,0]\n",
    "re_16 = re16[:,0]\n",
    "re_17 = re17[:,0]\n",
    "\n",
    "re_11 = np.reshape(re_11, (re_11.shape[0],1))\n",
    "re_12 = np.reshape(re_12, (re_12.shape[0],1))\n",
    "re_13 = np.reshape(re_13, (re_13.shape[0],1))\n",
    "re_14 = np.reshape(re_14, (re_14.shape[0],1))\n",
    "re_15 = np.reshape(re_15, (re_15.shape[0],1))\n",
    "re_16 = np.reshape(re_16, (re_16.shape[0],1))\n",
    "re_17 = np.reshape(re_17, (re_17.shape[0],1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "re21 = xgb.predict_proba(x_train)\n",
    "re22 = log.predict_proba(x_train)\n",
    "re23 = knn.predict_proba(x_train)\n",
    "re24 = rnf.predict_proba(x_train)\n",
    "re25 = ext.predict_proba(x_train)\n",
    "re26 = ada.predict_proba(x_train)\n",
    "re27 = lgb.predict_proba(x_train)\n",
    "\n",
    "re_21 = re21[:,0]\n",
    "re_22 = re22[:,0]\n",
    "re_23 = re23[:,0]\n",
    "re_24 = re24[:,0]\n",
    "re_25 = re25[:,0]\n",
    "re_26 = re26[:,0]\n",
    "re_27 = re27[:,0]\n",
    "\n",
    "re_21 = np.reshape(re_21, (re_21.shape[0],1))\n",
    "re_22 = np.reshape(re_22, (re_22.shape[0],1))\n",
    "re_23 = np.reshape(re_23, (re_23.shape[0],1))\n",
    "re_24 = np.reshape(re_24, (re_24.shape[0],1))\n",
    "re_25 = np.reshape(re_25, (re_25.shape[0],1))\n",
    "re_26 = np.reshape(re_26, (re_26.shape[0],1))\n",
    "re_27 = np.reshape(re_27, (re_27.shape[0],1))\n",
    "\n",
    "if(mo1 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_21), axis=1)\n",
    "if(mo2 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_22), axis=1)\n",
    "if(mo3 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_23), axis=1)\n",
    "if(mo4 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_24), axis=1)\n",
    "if(mo5 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_25), axis=1)\n",
    "if(mo6 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_26), axis=1)\n",
    "if(mo7 == 1):\n",
    "    xx_train = np.concatenate((xx_train, re_27), axis=1)\n",
    "\n",
    "if(mo1 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_11), axis=1)\n",
    "if(mo2 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_12), axis=1)\n",
    "if(mo3 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_13), axis=1)\n",
    "if(mo4 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_14), axis=1)\n",
    "if(mo5 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_15), axis=1)\n",
    "if(mo6 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_16), axis=1)\n",
    "if(mo7 == 1):\n",
    "    xx_val = np.concatenate((xx_val, re_17), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 23)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08831168831168831 0.7934990439770555 xgb2\n",
      "0.08955223880597013 0.19675090252707583 log2\n",
      "0.09177820267686423 0.862298195631529 rnf2\n",
      "0.09363295880149812 0.6378286683630195 ext2\n",
      "0.09674418604651162 0.17717346518335392 ada2\n",
      "0.09585253456221199 0.18298850574712647 lgb2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# xx_train.shape\n",
    "y_pre = xgb2.predict(xx_val)\n",
    "y_pre_2 = xgb2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'xgb2')\n",
    "y_pre = log2.predict(xx_val)\n",
    "y_pre_2 = log2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'log2')\n",
    "y_pre = rnf2.predict(xx_val)\n",
    "y_pre_2 = rnf2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'rnf2')\n",
    "y_pre = ext2.predict(xx_val)\n",
    "y_pre_2 = ext2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ext2')\n",
    "y_pre = ada2.predict(xx_val)\n",
    "y_pre_2 = ada2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ada2')\n",
    "y_pre = lgb2.predict(xx_val)\n",
    "y_pre_2 = lgb2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'lgb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06756756756756756 1.0 vote2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2.score(xx, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.46907649   4.25070317  -8.63694437 ...  85.          69.\n",
      "   85.        ]\n",
      " [  6.48856404   9.37957037  10.32791736 ...  64.          69.\n",
      "   64.        ]\n",
      " [  8.37392753 -10.14342267  -3.52753613 ...  93.          69.\n",
      "   93.        ]\n",
      " ...\n",
      " [  7.86551596   6.19525794   4.773955   ...  98.          69.\n",
      "   98.        ]\n",
      " [-10.41156442   1.40054826  -1.97349572 ...  80.          67.\n",
      "   80.        ]\n",
      " [  7.40908901  -7.3908382   10.78350645 ...  91.          69.\n",
      "   91.        ]] (10000, 31)\n"
     ]
    }
   ],
   "source": [
    "# predict process\n",
    "re1 = xgb.predict(X)\n",
    "re2 = log.predict(X)\n",
    "re3 = knn.predict(X)\n",
    "re4 = rnf.predict(X)\n",
    "re5 = ext.predict(X)\n",
    "re6 = ada.predict(X)\n",
    "re7 = svc.predict(X)\n",
    "\n",
    "re_1 = np.reshape(re1, (re1.shape[0],1))\n",
    "re_2 = np.reshape(re2, (re2.shape[0],1))\n",
    "re_3 = np.reshape(re3, (re3.shape[0],1))\n",
    "re_4 = np.reshape(re4, (re4.shape[0],1))\n",
    "re_5 = np.reshape(re5, (re5.shape[0],1))\n",
    "re_6 = np.reshape(re6, (re6.shape[0],1))\n",
    "re_7 = np.reshape(re7, (re7.shape[0],1))\n",
    "\n",
    "xx = np.concatenate((xx, re_1), axis=1)\n",
    "xx = np.concatenate((xx, re_2), axis=1)\n",
    "xx = np.concatenate((xx, re_3), axis=1)\n",
    "xx = np.concatenate((xx, re_4), axis=1)\n",
    "xx = np.concatenate((xx, re_5), axis=1)\n",
    "xx = np.concatenate((xx, re_6), axis=1)\n",
    "xx = np.concatenate((xx, re_7), axis=1)\n",
    "print(xx,xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = vote2.predect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_final, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790,)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**best_params1)\n",
    "log = LogisticRegression(**best_params2)\n",
    "knn = KNeighborsClassifier(**best_params3)\n",
    "rnf = RandomForestClassifier(**best_params4)\n",
    "ext = ExtraTreesClassifier(**best_params5)\n",
    "ada = AdaBoostClassifier(**best_params6)\n",
    "lgb = LGBMClassifier(**best_params7)\n",
    "# svc = SVC(**best_params8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2720, 172)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08822457163689391 0.1593798449612403 vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# vote_list = [('xgb', xgb), ('log', log), ('knn', knn), ('rnf', rnf), ('ext', ext), ('ada', ada), ('svc', svc),('lgb',lgb)]\n",
    "# vote_list = [('xgb', xgb), ('log', log), ('knn', knn), ('rnf', rnf), ('ext', ext), ('ada', ada), ('lgb',lgb)]\n",
    "vote_list = [('log', log), ('ada', ada), ('lgb',lgb)]\n",
    "vote = VotingClassifier(estimators=vote_list, voting='soft')\n",
    "vote.fit(x_sm, y_sm)\n",
    "# vote.fit(x_val, y_val)\n",
    "# y_pre = vote.predict(x_sm)\n",
    "y_pre = vote.predict(x_val)\n",
    "y_pre_2 = vote.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011363636363636364 0.9952153110047847 vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pre = vote.predict(x_val)\n",
    "y_pre_2 = vote.predict(x_train2)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train2, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.00546448,\n",
       "       0.        , 0.0273224 , 0.01092896, 0.00546448, 0.01092896,\n",
       "       0.00546448, 0.00546448, 0.03278688, 0.04918033, 0.01639344,\n",
       "       0.00546448, 0.03278688, 0.01092896, 0.01092896, 0.        ,\n",
       "       0.        , 0.        , 0.01639344, 0.00546448, 0.01639344,\n",
       "       0.01639344, 0.01092896, 0.00546448, 0.00546448, 0.        ,\n",
       "       0.01639344, 0.02185792, 0.02185792, 0.01092896, 0.01092896,\n",
       "       0.00546448, 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.01639344, 0.        , 0.00546448, 0.        , 0.        ,\n",
       "       0.00546448, 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.00546448, 0.        , 0.00546448, 0.        , 0.        ,\n",
       "       0.        , 0.00546448, 0.        , 0.01092896, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00546448, 0.00546448, 0.00546448, 0.        ,\n",
       "       0.00546448, 0.00546448, 0.01092896, 0.        , 0.        ,\n",
       "       0.01092896, 0.        , 0.        , 0.01639344, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01092896, 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.00546448, 0.01639344, 0.09289618,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02185792, 0.04918033, 0.03278688,\n",
       "       0.02185792, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01092896, 0.02185792, 0.01092896, 0.        ,\n",
       "       0.01092896, 0.00546448, 0.        , 0.        , 0.00546448,\n",
       "       0.        , 0.        , 0.00546448, 0.        , 0.00546448,\n",
       "       0.        , 0.        , 0.00546448, 0.        , 0.02185792,\n",
       "       0.02185792, 0.03825137, 0.03278688, 0.00546448, 0.00546448,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 64, 93, ..., 98, 80, 91])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032520325203252032"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, y_pre, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.00162866])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y, y_pre,pos_label=1, average=None)\n",
    "precision_score(y, y_pre,pos_label=1, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vote.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vote, 'vote.pkl') \n",
    "vote2 = joblib.load('vote.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote2 = joblib.load('vote.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb', RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=nan, n_estimators=100,\n",
       " ...obs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
