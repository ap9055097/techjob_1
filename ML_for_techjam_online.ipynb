{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('IsusV3.csv', delimiter = ',').reset_index(drop=True)\n",
    "# data\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10720, 135)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.drop(['Target'], axis=1).fillna(0)\n",
    "# data1 = data1.values\n",
    "y = data[['Target']].values\n",
    "data1.shape\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10720, 172)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "vec = DictVectorizer()\n",
    "x = vec.fit_transform(x).toarray()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.67342504 -0.47761992  0.84888102 ... -0.42825331 -0.12012834\n",
      "  -0.06184457]\n",
      " [-0.62596601  1.42233677  1.21213357 ... -0.01848268 -0.120761\n",
      "  -0.07734671]\n",
      " [ 0.69246549 -0.37815512  0.53151538 ... -0.12277241  0.01093889\n",
      "   0.63798686]\n",
      " ...\n",
      " [-0.65954272 -0.29226168  0.44286775 ... -0.39478502  0.3326532\n",
      "  -0.1125537 ]\n",
      " [-0.73531648 -0.23726458  0.01330267 ...  0.0015731   0.31945082\n",
      "  -0.16996018]\n",
      " [-0.73577693 -0.17884303  0.02231265 ... -0.03126159  0.26912862\n",
      "  -0.16303664]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]] (10720, 20) (10720, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20, svd_solver='randomized',random_state=42)\n",
    "x = pca.fit_transform(x,y)\n",
    "\n",
    "print(x,y,x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 20) (8000, 1) (2720, 20) (2720, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x[:8000][:]\n",
    "y_train = y[:8000][:]\n",
    "# x_train2 = x[6000:8000][:]\n",
    "# y_train2 = y[6000:8000][:]\n",
    "x_val = x[8000:][:]\n",
    "y_val = y[8000:][:]\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15018, 20) (15018,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE(ratio='minority')\n",
    "sm = SMOTE(random_state=42)\n",
    "# x_sm, y_sm = sm.fit_sample(x_train, y_train)\n",
    "# x_sm, y_sm = x_train, y_train\n",
    "x_sm, y_sm = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "print(x_sm.shape,y_sm.shape)\n",
    "\n",
    "\n",
    "# x_sm2, y_sm2 = sm.fit_sample(x_train2, y_train2)\n",
    "# print(x_sm2.shape,y_sm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_sm.shape\n",
    "# x_sm = x_sm[:,np.array([9,10,11,136,148,154,156,158,159])]\n",
    "# x_sm.shape\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=20, svd_solver='full',random_state=42)\n",
    "# x_sm = pca.fit_transform(x_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 20)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "n_jobs = -1\n",
    "n_iter = 50\n",
    "n_iter_nt = 3\n",
    "cv = 5\n",
    "seed=42\n",
    "# n_features= x_sm.shape[1]\n",
    "n_features= 20\n",
    "is_pca = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 20)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=20, svd_solver='full',random_state=42)\n",
    "fitt = pca.fit_transform(x_sm,y_sm)\n",
    "fitt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=20, random_state=42,\n",
       "  svd_solver='full', tol=0.0, whiten=False)), ('clf', RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto',...obs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20, svd_solver='full',random_state=42)\n",
    "estimators = [('reduce_dim',pca ), ('clf', ext)]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07400194741966894 0.19413465510119784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# v = DictVectorizer(sparse=False)\n",
    "# d = [{'height': 1, 'length': 0, 'width': 1},{'height': 2, 'length': 1, 'width': 0},{'height': 1, 'length': 3, 'width': 2}]\n",
    "# v.fit_transform(d)\n",
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score\n",
    "model = lgb\n",
    "model.fit(x_sm, y_sm)\n",
    "y_pre = model.predict(x_val)\n",
    "f1_1  = f1_score(y_val, y_pre, average='binary')\n",
    "y_pre_2 = model.predict(x_train)\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1_1,f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66653831 0.30894309] 0.0420353982300885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48774070143473863"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score , accuracy_score , roc_curve , auc\n",
    "y_pre.sum()\n",
    "recall = recall_score(y_val, y_pre,pos_label=1, average=None)\n",
    "prec = precision_score(y_val, y_pre,pos_label=1, average='binary')\n",
    "\n",
    "print(recall,prec)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pre, pos_label=1)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(nthreads=-1)\n",
    "\n",
    "objective = 'binary:logistic'\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'objective': [objective],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "xgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', xgb)]\n",
    "    xgb = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', log)]\n",
    "    log = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "# Parameter for KNeighborsClassifier\n",
    "params = {\n",
    "    \"n_neighbors\": st.randint(2, 50),\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    \"leaf_size\": st.randint(10, 30),\n",
    "    \"p\": st.randint(1, 2),\n",
    "}\n",
    "knn = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', knn)]\n",
    "    knn = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', rnf)]\n",
    "    rnf = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ExtraTreesClassifier()\n",
    "# \n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', ext)]\n",
    "    ext = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = AdaBoostClassifier()\n",
    "\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "    'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', ada)]\n",
    "    ada = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC()\n",
    "\n",
    "# Parameter for SVC\n",
    "params = {  \n",
    "    'C':[0.001, 0.01, 0.1, 1, 10], \n",
    "    'degree': st.randint(1, 10),\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True],\n",
    "    'tol': [1e-3],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "svc = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)\n",
    "if(is_pca):\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', svc)]\n",
    "    svc = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter for LGBMClassifier\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "estimator = LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "params = {  \n",
    "            \"boosting_type\": [\"gbdt\",\"rf\",\"dart\"],\n",
    "            \"colsample_bytree\": st.beta(10, 1),\n",
    "            \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "            \"max_depth\": st.randint(3, 30),\n",
    "            \"min_child_weight\": st.expon(0, 50),\n",
    "            \"n_estimators\": st.randint(3, 40),\n",
    "            \"num_leaves\": st.randint(30, 50),\n",
    "            'objective': ['binary'],\n",
    "            \"subsample\": st.beta(10, 1),\n",
    "            \"seed\": [seed],\n",
    "        }\n",
    "\n",
    "lgb = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs)\n",
    "if(is_pca):\n",
    "    print('asas')\n",
    "    estimators = [('reduce_dim', PCA(n_components=20, svd_solver='full')), ('clf', lgb)]\n",
    "    lgb = Pipeline(estimators)\n",
    "# lgb = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid=True, n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001CAAA32A7B8>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001CAAA32A5F8>, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': [42]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001CAA2AE4DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001CAA2AE4DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(1032, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(1032, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (1032, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=1032, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'640abdebb33940df8f533caa613f00a2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'640abdebb33940df8f533caa613f00a2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-529-d6d43bd1a4b6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>\n        result = <ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>, result=<ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", 'import pandas as pd', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", \"import pandas as pd\\ndata = pd.read_csv('IsusV2fo...', delimiter = ',').reset_index(drop=True)\\n# data\", \"data1 = data.drop(['Target'], axis=1).fillna(0)\\n...alues\\ny = data[['Target']].values\\ndata1.shape\\n# y\", \"x = data1.to_dict('records')\", 'from sklearn.feature_extraction import DictVecto...izer()\\nx = vec.fit_transform(x).toarray()\\nx.shape', 'print(x,y,x.shape,y.shape)', 'x_train = x[:8000][:]\\ny_train = y[:8000][:]\\nx_va...rain.shape,y_train.shape,x_val.shape,y_val.shape)', 'from imblearn.over_sampling import SMOTE\\n# smote..., y_train)\\nprint(x_sm,y_sm,x_sm.shape,y_sm.shape)', 'import os\\nimport numpy as np\\nimport datetime\\n\\nim...iter = 2\\ncv = 5\\nseed=42\\nn_features= x_sm.shape[1]', 'estimator = XGBClassifier(nthreads=-1)\\nobjective...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = LogisticRegression()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = KNeighborsClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = RandomForestClassifier()\\n# Parameter...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = ExtraTreesClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = AdaBoostClassifier()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = SVC()\\n# Parameter for SVC\\nparams = {...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', \"xgb.fit(x_sm,y_sm)\\nlog.fit(x_sm,y_sm)\\nknn.fit(x_..., y_pre_2, average='binary')\\nprint(f1,f1_2,'svc')\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", 'import pandas as pd', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", \"import pandas as pd\\ndata = pd.read_csv('IsusV2fo...', delimiter = ',').reset_index(drop=True)\\n# data\", \"data1 = data.drop(['Target'], axis=1).fillna(0)\\n...alues\\ny = data[['Target']].values\\ndata1.shape\\n# y\", \"x = data1.to_dict('records')\", 'from sklearn.feature_extraction import DictVecto...izer()\\nx = vec.fit_transform(x).toarray()\\nx.shape', 'print(x,y,x.shape,y.shape)', 'x_train = x[:8000][:]\\ny_train = y[:8000][:]\\nx_va...rain.shape,y_train.shape,x_val.shape,y_val.shape)', 'from imblearn.over_sampling import SMOTE\\n# smote..., y_train)\\nprint(x_sm,y_sm,x_sm.shape,y_sm.shape)', 'import os\\nimport numpy as np\\nimport datetime\\n\\nim...iter = 2\\ncv = 5\\nseed=42\\nn_features= x_sm.shape[1]', 'estimator = XGBClassifier(nthreads=-1)\\nobjective...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = LogisticRegression()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = KNeighborsClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = RandomForestClassifier()\\n# Parameter...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = ExtraTreesClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = AdaBoostClassifier()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = SVC()\\n# Parameter for SVC\\nparams = {...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', \"xgb.fit(x_sm,y_sm)\\nlog.fit(x_sm,y_sm)\\nknn.fit(x_..., y_pre_2, average='binary')\\nprint(f1,f1_2,'svc')\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nD:\\techjam\\<ipython-input-529-d6d43bd1a4b6> in <module>()\n      1 lgb.fit(x_sm,y_sm)\n      2 \n      3 xgb.fit(x_sm,y_sm)\n      4 log.fit(x_sm,y_sm)\n----> 5 knn.fit(x_sm,y_sm)\n      6 rnf.fit(x_sm,y_sm)\n      7 ext.fit(x_sm,y_sm)\n      8 ada.fit(x_sm,y_sm)\n      9 \n     10 # svc.fit(x_sm,y_sm)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...turn_train_score='warn', scoring=None, verbose=0), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sun Sep 23 21:35:23 2018\nPID: 11396            Python 3.6.5: C:\\Users\\EBM_IT_01\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, train=array([    0,     1,     2, ..., 15015, 15016, 15017]), test=array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), verbose=0, parameters={'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), *args=(memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.])), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of KNeighbor..._neighbors=8, p=1,\n           weights='uniform')>\n        args = (memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        self.predict = <bound method KNeighborsClassifier.predict of KN..._neighbors=8, p=1,\n           weights='uniform')>\n        X = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]))\n    140         y : array of shape [n_samples] or [n_samples, n_outputs]\n    141             Class labels for each data sample.\n    142         \"\"\"\n    143         X = check_array(X, accept_sparse='csr')\n    144 \n--> 145         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei..._neighbors=8, p=1,\n           weights='uniform')>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n    146 \n    147         classes_ = self.classes_\n    148         _y = self._y\n    149         if not self.outputs_2d_:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), n_neighbors=8, return_distance=True)\n    358             else:\n    359                 dist = pairwise_distances(\n    360                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n    361                     **self.effective_metric_params_)\n    362 \n--> 363             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n        neigh_ind = undefined\n        dist = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        n_neighbors = 8\n    364             neigh_ind = neigh_ind[:, :n_neighbors]\n    365             # argpartition doesn't guarantee sorted order, so we sort again\n    366             neigh_ind = neigh_ind[\n    367                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in argpartition(a=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), kth=7, axis=1, kind='introselect', order=None)\n    726     >>> x = [3, 4, 2, 1]\n    727     >>> np.array(x)[np.argpartition(x, 3)]\n    728     array([2, 1, 3, 4])\n    729 \n    730     \"\"\"\n--> 731     return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n        a = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        kth = 7\n        axis = 1\n        kind = 'introselect'\n        order = None\n    732 \n    733 \n    734 def sort(a, axis=-1, kind='quicksort', order=None):\n    735     \"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in _wrapfunc(obj=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), method='argpartition', *args=(7,), **kwds={'axis': 1, 'kind': 'introselect', 'order': None})\n     47     return result\n     48 \n     49 \n     50 def _wrapfunc(obj, method, *args, **kwds):\n     51     try:\n---> 52         return getattr(obj, method)(*args, **kwds)\n        obj = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        method = 'argpartition'\n        args = (7,)\n        kwds = {'axis': 1, 'kind': 'introselect', 'order': None}\n     53 \n     54     # An AttributeError occurs if the object does not have\n     55     # such a method in its class.\n     56 \n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 492, in _fit_and_score\n    is_multimetric)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 553, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 244, in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 349, in score\n    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\", line 145, in predict\n    neigh_dist, neigh_ind = self.kneighbors(X)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 363, in kneighbors\n    neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 731, in argpartition\n    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 52, in _wrapfunc\n    return getattr(obj, method)(*args, **kwds)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sun Sep 23 21:35:23 2018\nPID: 11396            Python 3.6.5: C:\\Users\\EBM_IT_01\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, train=array([    0,     1,     2, ..., 15015, 15016, 15017]), test=array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), verbose=0, parameters={'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), *args=(memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.])), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of KNeighbor..._neighbors=8, p=1,\n           weights='uniform')>\n        args = (memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        self.predict = <bound method KNeighborsClassifier.predict of KN..._neighbors=8, p=1,\n           weights='uniform')>\n        X = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]))\n    140         y : array of shape [n_samples] or [n_samples, n_outputs]\n    141             Class labels for each data sample.\n    142         \"\"\"\n    143         X = check_array(X, accept_sparse='csr')\n    144 \n--> 145         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei..._neighbors=8, p=1,\n           weights='uniform')>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n    146 \n    147         classes_ = self.classes_\n    148         _y = self._y\n    149         if not self.outputs_2d_:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), n_neighbors=8, return_distance=True)\n    358             else:\n    359                 dist = pairwise_distances(\n    360                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n    361                     **self.effective_metric_params_)\n    362 \n--> 363             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n        neigh_ind = undefined\n        dist = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        n_neighbors = 8\n    364             neigh_ind = neigh_ind[:, :n_neighbors]\n    365             # argpartition doesn't guarantee sorted order, so we sort again\n    366             neigh_ind = neigh_ind[\n    367                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in argpartition(a=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), kth=7, axis=1, kind='introselect', order=None)\n    726     >>> x = [3, 4, 2, 1]\n    727     >>> np.array(x)[np.argpartition(x, 3)]\n    728     array([2, 1, 3, 4])\n    729 \n    730     \"\"\"\n--> 731     return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n        a = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        kth = 7\n        axis = 1\n        kind = 'introselect'\n        order = None\n    732 \n    733 \n    734 def sort(a, axis=-1, kind='quicksort', order=None):\n    735     \"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in _wrapfunc(obj=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), method='argpartition', *args=(7,), **kwds={'axis': 1, 'kind': 'introselect', 'order': None})\n     47     return result\n     48 \n     49 \n     50 def _wrapfunc(obj, method, *args, **kwds):\n     51     try:\n---> 52         return getattr(obj, method)(*args, **kwds)\n        obj = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        method = 'argpartition'\n        args = (7,)\n        kwds = {'axis': 1, 'kind': 'introselect', 'order': None}\n     53 \n     54     # An AttributeError occurs if the object does not have\n     55     # such a method in its class.\n     56 \n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Sun Sep 23 21:35:23 2018\nPID: 11396            Python 3.6.5: C:\\Users\\EBM_IT_01\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, train=array([    0,     1,     2, ..., 15015, 15016, 15017]), test=array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), verbose=0, parameters={'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), *args=(memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.])), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of KNeighbor..._neighbors=8, p=1,\n           weights='uniform')>\n        args = (memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        self.predict = <bound method KNeighborsClassifier.predict of KN..._neighbors=8, p=1,\n           weights='uniform')>\n        X = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]))\n    140         y : array of shape [n_samples] or [n_samples, n_outputs]\n    141             Class labels for each data sample.\n    142         \"\"\"\n    143         X = check_array(X, accept_sparse='csr')\n    144 \n--> 145         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei..._neighbors=8, p=1,\n           weights='uniform')>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n    146 \n    147         classes_ = self.classes_\n    148         _y = self._y\n    149         if not self.outputs_2d_:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), n_neighbors=8, return_distance=True)\n    358             else:\n    359                 dist = pairwise_distances(\n    360                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n    361                     **self.effective_metric_params_)\n    362 \n--> 363             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n        neigh_ind = undefined\n        dist = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        n_neighbors = 8\n    364             neigh_ind = neigh_ind[:, :n_neighbors]\n    365             # argpartition doesn't guarantee sorted order, so we sort again\n    366             neigh_ind = neigh_ind[\n    367                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in argpartition(a=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), kth=7, axis=1, kind='introselect', order=None)\n    726     >>> x = [3, 4, 2, 1]\n    727     >>> np.array(x)[np.argpartition(x, 3)]\n    728     array([2, 1, 3, 4])\n    729 \n    730     \"\"\"\n--> 731     return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n        a = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        kth = 7\n        axis = 1\n        kind = 'introselect'\n        order = None\n    732 \n    733 \n    734 def sort(a, axis=-1, kind='quicksort', order=None):\n    735     \"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in _wrapfunc(obj=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), method='argpartition', *args=(7,), **kwds={'axis': 1, 'kind': 'introselect', 'order': None})\n     47     return result\n     48 \n     49 \n     50 def _wrapfunc(obj, method, *args, **kwds):\n     51     try:\n---> 52         return getattr(obj, method)(*args, **kwds)\n        obj = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        method = 'argpartition'\n        args = (7,)\n        kwds = {'axis': 1, 'kind': 'introselect', 'order': None}\n     53 \n     54     # An AttributeError occurs if the object does not have\n     55     # such a method in its class.\n     56 \n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-529-d6d43bd1a4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrnf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001CAA2AE4DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001CAA2AE4DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(1032, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(1032, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (1032, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=1032, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'640abdebb33940df8f533caa613f00a2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'640abdebb33940df8f533caa613f00a2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 9, 23, 14, 33, 22, 175154, tzinfo=tzutc()), 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'session': '640abdebb33940df8f533caa613f00a2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'c500102957754601ba7c0ff9b6684f08', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"lgb.fit(x_sm,y_sm)\\n\\nxgb.fit(x_sm,y_sm)\\nlog.fit(x... 'svc.pkl') \\n# vote2 = joblib.load('vote.pkl') \\n\\n\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-529-d6d43bd1a4b6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>\n        result = <ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>, result=<ExecutionResult object at 1caaa24f710, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001CAAC1FDD20, file \"<ipython-input-529-d6d43bd1a4b6>\", line 5>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", 'import pandas as pd', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", \"import pandas as pd\\ndata = pd.read_csv('IsusV2fo...', delimiter = ',').reset_index(drop=True)\\n# data\", \"data1 = data.drop(['Target'], axis=1).fillna(0)\\n...alues\\ny = data[['Target']].values\\ndata1.shape\\n# y\", \"x = data1.to_dict('records')\", 'from sklearn.feature_extraction import DictVecto...izer()\\nx = vec.fit_transform(x).toarray()\\nx.shape', 'print(x,y,x.shape,y.shape)', 'x_train = x[:8000][:]\\ny_train = y[:8000][:]\\nx_va...rain.shape,y_train.shape,x_val.shape,y_val.shape)', 'from imblearn.over_sampling import SMOTE\\n# smote..., y_train)\\nprint(x_sm,y_sm,x_sm.shape,y_sm.shape)', 'import os\\nimport numpy as np\\nimport datetime\\n\\nim...iter = 2\\ncv = 5\\nseed=42\\nn_features= x_sm.shape[1]', 'estimator = XGBClassifier(nthreads=-1)\\nobjective...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = LogisticRegression()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = KNeighborsClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = RandomForestClassifier()\\n# Parameter...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = ExtraTreesClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = AdaBoostClassifier()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = SVC()\\n# Parameter for SVC\\nparams = {...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', \"xgb.fit(x_sm,y_sm)\\nlog.fit(x_sm,y_sm)\\nknn.fit(x_..., y_pre_2, average='binary')\\nprint(f1,f1_2,'svc')\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", 'import pandas as pd', \"data = pd.read_csv('IsusV2forTrain.csv', delimiter = ',').reset_index(drop=True)\\n# data\", \"import pandas as pd\\ndata = pd.read_csv('IsusV2fo...', delimiter = ',').reset_index(drop=True)\\n# data\", \"data1 = data.drop(['Target'], axis=1).fillna(0)\\n...alues\\ny = data[['Target']].values\\ndata1.shape\\n# y\", \"x = data1.to_dict('records')\", 'from sklearn.feature_extraction import DictVecto...izer()\\nx = vec.fit_transform(x).toarray()\\nx.shape', 'print(x,y,x.shape,y.shape)', 'x_train = x[:8000][:]\\ny_train = y[:8000][:]\\nx_va...rain.shape,y_train.shape,x_val.shape,y_val.shape)', 'from imblearn.over_sampling import SMOTE\\n# smote..., y_train)\\nprint(x_sm,y_sm,x_sm.shape,y_sm.shape)', 'import os\\nimport numpy as np\\nimport datetime\\n\\nim...iter = 2\\ncv = 5\\nseed=42\\nn_features= x_sm.shape[1]', 'estimator = XGBClassifier(nthreads=-1)\\nobjective...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = LogisticRegression()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = KNeighborsClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = RandomForestClassifier()\\n# Parameter...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = ExtraTreesClassifier()\\n# Parameter f...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = AdaBoostClassifier()\\n# Parameter for...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', 'estimator = SVC()\\n# Parameter for SVC\\nparams = {...tor, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) ', \"xgb.fit(x_sm,y_sm)\\nlog.fit(x_sm,y_sm)\\nknn.fit(x_..., y_pre_2, average='binary')\\nprint(f1,f1_2,'svc')\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nD:\\techjam\\<ipython-input-529-d6d43bd1a4b6> in <module>()\n      1 lgb.fit(x_sm,y_sm)\n      2 \n      3 xgb.fit(x_sm,y_sm)\n      4 log.fit(x_sm,y_sm)\n----> 5 knn.fit(x_sm,y_sm)\n      6 rnf.fit(x_sm,y_sm)\n      7 ext.fit(x_sm,y_sm)\n      8 ada.fit(x_sm,y_sm)\n      9 \n     10 # svc.fit(x_sm,y_sm)\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=5, error_score='raise',\n  ...turn_train_score='warn', scoring=None, verbose=0), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Sun Sep 23 21:35:23 2018\nPID: 11396            Python 3.6.5: C:\\Users\\EBM_IT_01\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]), {'score': <function _passthrough_scorer>}, array([    0,     1,     2, ..., 15015, 15016, 15017]), array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), 0, {'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, train=array([    0,     1,     2, ..., 15015, 15016, 15017]), test=array([ 3240,  3241,  3242, ..., 12012, 12013, 12014]), verbose=0, parameters={'algorithm': 'brute', 'leaf_size': 23, 'n_neighbors': 8, 'p': 1, 'weights': 'uniform'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X_test=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y_test=array([1., 0., 0., ..., 1., 1., 1.]), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform')\n        X_test = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        y_test = array([1., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), *args=(memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.])), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of KNeighbor..._neighbors=8, p=1,\n           weights='uniform')>\n        args = (memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), array([1., 0., 0., ..., 1., 1., 1.]))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), y=array([1., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array([1., 0., 0., ..., 1., 1., 1.])\n        self.predict = <bound method KNeighborsClassifier.predict of KN..._neighbors=8, p=1,\n           weights='uniform')>\n        X = memmap([[ 6.73425036e-01, -4.77619916e-01,  8.48...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]))\n    140         y : array of shape [n_samples] or [n_samples, n_outputs]\n    141             Class labels for each data sample.\n    142         \"\"\"\n    143         X = check_array(X, accept_sparse='csr')\n    144 \n--> 145         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei..._neighbors=8, p=1,\n           weights='uniform')>\n        X = array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]])\n    146 \n    147         classes_ = self.classes_\n    148         _y = self._y\n    149         if not self.outputs_2d_:\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='brute', leaf_siz...n_neighbors=8, p=1,\n           weights='uniform'), X=array([[ 6.73425036e-01, -4.77619916e-01,  8.488...25498601e-04, -5.67182465e-02,  6.81635903e-03]]), n_neighbors=8, return_distance=True)\n    358             else:\n    359                 dist = pairwise_distances(\n    360                     X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n    361                     **self.effective_metric_params_)\n    362 \n--> 363             neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n        neigh_ind = undefined\n        dist = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        n_neighbors = 8\n    364             neigh_ind = neigh_ind[:, :n_neighbors]\n    365             # argpartition doesn't guarantee sorted order, so we sort again\n    366             neigh_ind = neigh_ind[\n    367                 sample_range, np.argsort(dist[sample_range, neigh_ind])]\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in argpartition(a=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), kth=7, axis=1, kind='introselect', order=None)\n    726     >>> x = [3, 4, 2, 1]\n    727     >>> np.array(x)[np.argpartition(x, 3)]\n    728     array([2, 1, 3, 4])\n    729 \n    730     \"\"\"\n--> 731     return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\n        a = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        kth = 7\n        axis = 1\n        kind = 'introselect'\n        order = None\n    732 \n    733 \n    734 def sort(a, axis=-1, kind='quicksort', order=None):\n    735     \"\"\"\n\n...........................................................................\nC:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py in _wrapfunc(obj=array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]]), method='argpartition', *args=(7,), **kwds={'axis': 1, 'kind': 'introselect', 'order': None})\n     47     return result\n     48 \n     49 \n     50 def _wrapfunc(obj, method, *args, **kwds):\n     51     try:\n---> 52         return getattr(obj, method)(*args, **kwds)\n        obj = array([[ 0.        ,  8.69686658,  7.91309965, ....  9.76537335,\n         6.93698378,  0.        ]])\n        method = 'argpartition'\n        args = (7,)\n        kwds = {'axis': 1, 'kind': 'introselect', 'order': None}\n     53 \n     54     # An AttributeError occurs if the object does not have\n     55     # such a method in its class.\n     56 \n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "lgb.fit(x_sm,y_sm)\n",
    "\n",
    "xgb.fit(x_sm,y_sm)\n",
    "log.fit(x_sm,y_sm)\n",
    "knn.fit(x_sm,y_sm)\n",
    "rnf.fit(x_sm,y_sm)\n",
    "ext.fit(x_sm,y_sm)\n",
    "ada.fit(x_sm,y_sm)\n",
    "\n",
    "# svc.fit(x_sm,y_sm)\n",
    "\n",
    "# y_pre_2 = xgb.predict(x_train)\n",
    "# f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "# joblib.dump(xgb, 'xgb.pkl') \n",
    "# joblib.dump(log, 'log.pkl') \n",
    "# joblib.dump(knn, 'knn.pkl') \n",
    "# joblib.dump(rnf, 'rnf.pkl') \n",
    "# joblib.dump(ext, 'ext.pkl') \n",
    "# joblib.dump(ada, 'ada.pkl') \n",
    "# joblib.dump(svc, 'svc.pkl') \n",
    "# vote2 = joblib.load('vote.pkl') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb.pkl']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb, 'xgb.pkl') \n",
    "joblib.dump(log, 'log.pkl') \n",
    "joblib.dump(knn, 'knn.pkl') \n",
    "joblib.dump(rnf, 'rnf.pkl') \n",
    "joblib.dump(ext, 'ext.pkl') \n",
    "joblib.dump(ada, 'ada.pkl') \n",
    "joblib.dump(lgb, 'lgb.pkl') \n",
    "# joblib.dump(svc, 'svc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params1 = xgb.best_params_\n",
    "best_params2 = log.best_params_\n",
    "best_params3 = knn.best_params_\n",
    "best_params4 = rnf.best_params_\n",
    "best_params5 = ext.best_params_\n",
    "best_params6 = ada.best_params_\n",
    "best_params7 = lgb.best_params_\n",
    "# best_params8 = svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.66,\n",
       " 'learning_rate': 0.005,\n",
       " 'n_estimators': 40,\n",
       " 'num_leaves': 16,\n",
       " 'objective': 'binary',\n",
       " 'random_state': 501,\n",
       " 'reg_alpha': 1.2,\n",
       " 'reg_lambda': 1.2,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = joblib.load('xgb.pkl')\n",
    "# log = joblib.load('log.pkl') \n",
    "# knn = joblib.load('knn.pkl') \n",
    "# rnf = joblib.load('rnf.pkl') \n",
    "# ext = joblib.load('ext.pkl') \n",
    "# ada = joblib.load('ada.pkl') \n",
    "# svc = joblib.load('svc.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val[:,np.array([9,10,11,136,148,154,156,158,159])]\n",
    "x_train = x_train[:,np.array([9,10,11,136,148,154,156,158,159])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score\n",
    "y_pre = xgb.predict(x_val)\n",
    "y_pre_2 = xgb.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'xgb')\n",
    "y_pre = log.predict(x_val)\n",
    "y_pre_2 = log.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'log')\n",
    "y_pre = knn.predict(x_val)\n",
    "y_pre_2 = knn.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'knn')\n",
    "y_pre = rnf.predict(x_val)\n",
    "y_pre_2 = rnf.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'rnf')\n",
    "y_pre = ext.predict(x_val)\n",
    "y_pre_2 = ext.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ext')\n",
    "y_pre = ada.predict(x_val)\n",
    "y_pre_2 = ada.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ada')\n",
    "y_pre = lgb.predict(x_val)\n",
    "y_pre_2 = lgb.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'lgb')\n",
    "# y_pre = svc.predict(x_val)\n",
    "# y_pre_2 = svc.predict(x_train)\n",
    "# f1  = f1_score(y_val, y_pre, average='binary')\n",
    "# f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "# print(f1,f1_2,'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00834905, 0.        , 0.        , 0.        , 0.00920586,\n",
       "       0.01012321, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01370775, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00632684, 0.        ,\n",
       "       0.        , 0.04433919, 0.00605415, 0.        , 0.        ,\n",
       "       0.02054843, 0.        , 0.03315179, 0.08930309, 0.02958396,\n",
       "       0.08670702, 0.05670399, 0.01239347, 0.02800984, 0.        ,\n",
       "       0.01946984, 0.01227604, 0.02419606, 0.        , 0.        ,\n",
       "       0.04129673, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02704987, 0.        , 0.01335804, 0.        , 0.        ,\n",
       "       0.02205143, 0.        , 0.        , 0.        , 0.01327537,\n",
       "       0.03839346, 0.        , 0.0161746 , 0.        , 0.        ,\n",
       "       0.01438881, 0.        , 0.01830282, 0.02040816, 0.0214357 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01855491, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00870003, 0.        , 0.        , 0.        , 0.00995637,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01249901, 0.03147816, 0.01661855,\n",
       "       0.        , 0.0213823 , 0.00669973, 0.        , 0.01074305,\n",
       "       0.        , 0.        , 0.00908235, 0.0111856 , 0.01626681,\n",
       "       0.        , 0.        , 0.        , 0.01153407, 0.        ,\n",
       "       0.03818805, 0.        , 0.        , 0.        , 0.0032188 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01730762, 0.        ])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = log.best_estimator_.coef_\n",
    "a = ada.best_estimator_.feature_importances_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5   9  10  31  38  41  42  45  47  48  49  50  51  52  53  55  56  57\n",
      "  60  65  67  70  74  75  77  80  82  83  84 120 125 129 142 143 144 146\n",
      " 147 149 152 153 154 158 160 164 170] [  9  10  11 136 148 154 156 158 159]\n"
     ]
    }
   ],
   "source": [
    "# print(np.argwhere(a>0.01),np.argwhere(a<-0.01))\n",
    "# print(np.argwhere(a!=0))\n",
    "b = np.argwhere(a!=0)\n",
    "# np.reshape(b,(b.shape[]))\n",
    "b = b.ravel()\n",
    "print(b,np.array([9,10,11,136,148,154,156,158,159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   9]\n",
      " [  0  10]\n",
      " [  0  11]\n",
      " [  0 136]\n",
      " [  0 148]\n",
      " [  0 156]\n",
      " [  0 158]\n",
      " [  0 159]] [[  0 154]]\n"
     ]
    }
   ],
   "source": [
    "print(np.argwhere(a>0.01),np.argwhere(a<-0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 45)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sm2 = x_sm[:,np.array(b)]\n",
    "x_sm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = xgb.predict_proba(x_sm)\n",
    "re2 = log.predict_proba(x_sm)\n",
    "re3 = knn.predict_proba(x_sm)\n",
    "re4 = rnf.predict_proba(x_sm)\n",
    "re5 = ext.predict_proba(x_sm)\n",
    "re6 = ada.predict_proba(x_sm)\n",
    "re7 = lgb.predict_proba(x_sm)\n",
    "\n",
    "# re8 = svc.predict_proba(x_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = x_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = xgb.predict_proba(x_val)\n",
    "# test[:,0]\n",
    "\n",
    "\n",
    "re_1 = re1[:,0]\n",
    "re_2 = re2[:,0]\n",
    "re_3 = re3[:,0]\n",
    "re_4 = re4[:,0]\n",
    "re_5 = re5[:,0]\n",
    "re_6 = re6[:,0]\n",
    "re_7 = re7[:,0]\n",
    "\n",
    "\n",
    "re_1 = np.reshape(re_1, (re_1.shape[0],1))\n",
    "re_2 = np.reshape(re_2, (re_2.shape[0],1))\n",
    "re_3 = np.reshape(re_3, (re_3.shape[0],1))\n",
    "re_4 = np.reshape(re_4, (re_4.shape[0],1))\n",
    "re_5 = np.reshape(re_5, (re_5.shape[0],1))\n",
    "re_6 = np.reshape(re_6, (re_6.shape[0],1))\n",
    "re_7 = np.reshape(re_7, (re_7.shape[0],1))\n",
    "# xx = x_sm\n",
    "xx = np.concatenate((xx, re_1), axis=1)\n",
    "xx = np.concatenate((xx, re_2), axis=1)\n",
    "xx = np.concatenate((xx, re_3), axis=1)\n",
    "xx = np.concatenate((xx, re_4), axis=1)\n",
    "xx = np.concatenate((xx, re_5), axis=1)\n",
    "xx = np.concatenate((xx, re_6), axis=1)\n",
    "xx = np.concatenate((xx, re_7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 27)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "n_iter = 30\n",
    "cv = 5\n",
    "seed=42\n",
    "# n_features=xx.shape[1]\n",
    "n_features= 20+7\n",
    "\n",
    "estimator = XGBClassifier(nthreads=-1)\n",
    "objective = 'binary:logistic'\n",
    "\n",
    "# Parameter for XGBoost\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 30),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": st.beta(10, 1),\n",
    "    \"subsample\": st.beta(10, 1),\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'objective': [objective],\n",
    "    'scale_pos_weight': st.randint(0, 2),\n",
    "    \"min_child_weight\": st.expon(0, 50),\n",
    "    \"seed\": [seed],\n",
    "}\n",
    "xgb2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = LogisticRegression()\n",
    "# Parameter for LogisticRegression\n",
    "params = {\n",
    "    \"penalty\": ['l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    \"max_iter\": st.randint(50, 100),\n",
    "    'random_state': [seed],\n",
    "} \n",
    "log2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "# Parameter for RandomForestClassifier\n",
    "params = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "rnf2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = ExtraTreesClassifier()\n",
    "# Parameter for ExtraTreesClassifier\n",
    "params = {\n",
    "    \"n_estimators\": st.randint(5, 50),\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": st.randint(1, n_features),\n",
    "    \"min_samples_split\": st.randint(2, 10),\n",
    "    \"min_samples_leaf\": st.randint(1, n_features),\n",
    "    \"bootstrap\": [True],\n",
    "    \"oob_score\": [True],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ext2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter) \n",
    "\n",
    "estimator = AdaBoostClassifier()\n",
    "# Parameter for AdaBoost\n",
    "params = { \n",
    "    'n_estimators':st.randint(10, 100), \n",
    "    'learning_rate':st.beta(10, 1), \n",
    "    'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'random_state': [seed],\n",
    "}\n",
    "ada2 = RandomizedSearchCV(estimator, params, cv=cv,n_jobs=n_jobs, n_iter=n_iter)\n",
    "\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [42,502], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "estimator = LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "lgb2 = GridSearchCV(estimator, gridParams, verbose=0, cv=cv,n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_bin=512,\n",
       "        max_depth=-1, min_child_samples=5, min_child_weight=1,\n",
       "        min_split_gain=0.5, n_estimators=100, n_jobs=3, num_leaves=31,\n",
       "        objective='binary', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, scale_pos_weight=1, silent=True, subsample=1,\n",
       "        subsample_for_bin=200, subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.005], 'n_estimators': [40], 'num_leaves': [6, 8, 12, 16], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'random_state': [42, 502], 'colsample_bytree': [0.65, 0.66], 'subsample': [0.7, 0.75], 'reg_alpha': [1, 1.2], 'reg_lambda': [1, 1.2, 1.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2.fit(xx,y_sm)\n",
    "log2.fit(xx,y_sm)\n",
    "rnf2.fit(xx,y_sm)\n",
    "ext2.fit(xx,y_sm)\n",
    "ada2.fit(xx,y_sm)\n",
    "lgb2.fit(xx,y_sm)\n",
    "\n",
    "\n",
    "# joblib.dump(xgb2, 'xgb2.pkl') \n",
    "# joblib.dump(log2, 'log2.pkl') \n",
    "# joblib.dump(rnf2, 'rnf2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15018, 179)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 vote2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vote_list = [('xgb2', xgb2), ('log2', log2), ('rnf2', rnf2), ('ext2', ext2)]\n",
    "vote2 = VotingClassifier(estimators=vote_list, voting='soft')\n",
    "# vote2.fit(xx, y_sm)\n",
    "# vote2.fit(xx_val, y_val)\n",
    "# joblib.dump(vote2, 'vote2.pkl') \n",
    "# vote2.feature_importances_\n",
    "y_pre = vote2.predict(xx_val)\n",
    "y_pre_2 = vote2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15096, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_val.shape\n",
    "re_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx_val = x_val[:,np.array(b)]\n",
    "# xx_train = x_train[:,np.array(b)]\n",
    "\n",
    "xx_val = x_val\n",
    "xx_train = x_train\n",
    "\n",
    "# re1 = xgb2.predict_proba(x_sm)\n",
    "# re2 = log.predict_proba(x_sm)\n",
    "# re3 = knn.predict_proba(x_sm)\n",
    "\n",
    "re11 = xgb.predict_proba(x_val)\n",
    "re12 = log.predict_proba(x_val)\n",
    "re13 = knn.predict_proba(x_val)\n",
    "re14 = rnf.predict_proba(x_val)\n",
    "re15 = ext.predict_proba(x_val)\n",
    "re16 = ada.predict_proba(x_val)\n",
    "re17 = lgb.predict_proba(x_val)\n",
    "\n",
    "re_11 = re11[:,0]\n",
    "re_12 = re12[:,0]\n",
    "re_13 = re13[:,0]\n",
    "re_14 = re14[:,0]\n",
    "re_15 = re15[:,0]\n",
    "re_16 = re16[:,0]\n",
    "re_17 = re17[:,0]\n",
    "\n",
    "re_11 = np.reshape(re_11, (re_11.shape[0],1))\n",
    "re_12 = np.reshape(re_12, (re_12.shape[0],1))\n",
    "re_13 = np.reshape(re_13, (re_13.shape[0],1))\n",
    "re_14 = np.reshape(re_14, (re_14.shape[0],1))\n",
    "re_15 = np.reshape(re_15, (re_15.shape[0],1))\n",
    "re_16 = np.reshape(re_16, (re_16.shape[0],1))\n",
    "re_17 = np.reshape(re_17, (re_17.shape[0],1))\n",
    "\n",
    "\n",
    "xx_val = np.concatenate((xx_val, re_11), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_12), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_13), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_14), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_15), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_16), axis=1)\n",
    "xx_val = np.concatenate((xx_val, re_17), axis=1)\n",
    "\n",
    "re21 = xgb.predict_proba(x_train)\n",
    "re22 = log.predict_proba(x_train)\n",
    "re23 = knn.predict_proba(x_train)\n",
    "re24 = rnf.predict_proba(x_train)\n",
    "re25 = ext.predict_proba(x_train)\n",
    "re26 = ada.predict_proba(x_train)\n",
    "re27 = lgb.predict_proba(x_train)\n",
    "\n",
    "re_21 = re21[:,0]\n",
    "re_22 = re22[:,0]\n",
    "re_23 = re23[:,0]\n",
    "re_24 = re24[:,0]\n",
    "re_25 = re25[:,0]\n",
    "re_26 = re26[:,0]\n",
    "re_27 = re27[:,0]\n",
    "\n",
    "re_21 = np.reshape(re_21, (re_21.shape[0],1))\n",
    "re_22 = np.reshape(re_22, (re_22.shape[0],1))\n",
    "re_23 = np.reshape(re_23, (re_23.shape[0],1))\n",
    "re_24 = np.reshape(re_24, (re_24.shape[0],1))\n",
    "re_25 = np.reshape(re_25, (re_25.shape[0],1))\n",
    "re_26 = np.reshape(re_26, (re_26.shape[0],1))\n",
    "re_27 = np.reshape(re_27, (re_27.shape[0],1))\n",
    "\n",
    "\n",
    "xx_train = np.concatenate((xx_train, re_21), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_22), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_23), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_24), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_25), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_26), axis=1)\n",
    "xx_train = np.concatenate((xx_train, re_27), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 27)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08759124087591241 1.0 xgb2\n",
      "0.05183585313174945 1.0 log2\n",
      "0.05829596412556053 1.0 rnf2\n",
      "0.07963246554364471 1.0 ext2\n",
      "0.05803571428571429 1.0 ada2\n",
      "0.034482758620689655 1.0 lgb2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# xx_train.shape\n",
    "y_pre = xgb2.predict(xx_val)\n",
    "y_pre_2 = xgb2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'xgb2')\n",
    "y_pre = log2.predict(xx_val)\n",
    "y_pre_2 = log2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'log2')\n",
    "y_pre = rnf2.predict(xx_val)\n",
    "y_pre_2 = rnf2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'rnf2')\n",
    "y_pre = ext2.predict(xx_val)\n",
    "y_pre_2 = ext2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ext2')\n",
    "y_pre = ada2.predict(xx_val)\n",
    "y_pre_2 = ada2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'ada2')\n",
    "y_pre = lgb2.predict(xx_val)\n",
    "y_pre_2 = lgb2.predict(xx_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'lgb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06756756756756756 1.0 vote2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2.score(xx, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.46907649   4.25070317  -8.63694437 ...  85.          69.\n",
      "   85.        ]\n",
      " [  6.48856404   9.37957037  10.32791736 ...  64.          69.\n",
      "   64.        ]\n",
      " [  8.37392753 -10.14342267  -3.52753613 ...  93.          69.\n",
      "   93.        ]\n",
      " ...\n",
      " [  7.86551596   6.19525794   4.773955   ...  98.          69.\n",
      "   98.        ]\n",
      " [-10.41156442   1.40054826  -1.97349572 ...  80.          67.\n",
      "   80.        ]\n",
      " [  7.40908901  -7.3908382   10.78350645 ...  91.          69.\n",
      "   91.        ]] (10000, 31)\n"
     ]
    }
   ],
   "source": [
    "# predict process\n",
    "re1 = xgb.predict(X)\n",
    "re2 = log.predict(X)\n",
    "re3 = knn.predict(X)\n",
    "re4 = rnf.predict(X)\n",
    "re5 = ext.predict(X)\n",
    "re6 = ada.predict(X)\n",
    "re7 = svc.predict(X)\n",
    "\n",
    "re_1 = np.reshape(re1, (re1.shape[0],1))\n",
    "re_2 = np.reshape(re2, (re2.shape[0],1))\n",
    "re_3 = np.reshape(re3, (re3.shape[0],1))\n",
    "re_4 = np.reshape(re4, (re4.shape[0],1))\n",
    "re_5 = np.reshape(re5, (re5.shape[0],1))\n",
    "re_6 = np.reshape(re6, (re6.shape[0],1))\n",
    "re_7 = np.reshape(re7, (re7.shape[0],1))\n",
    "\n",
    "xx = np.concatenate((xx, re_1), axis=1)\n",
    "xx = np.concatenate((xx, re_2), axis=1)\n",
    "xx = np.concatenate((xx, re_3), axis=1)\n",
    "xx = np.concatenate((xx, re_4), axis=1)\n",
    "xx = np.concatenate((xx, re_5), axis=1)\n",
    "xx = np.concatenate((xx, re_6), axis=1)\n",
    "xx = np.concatenate((xx, re_7), axis=1)\n",
    "print(xx,xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = vote2.predect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_final, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3790,)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**best_params1)\n",
    "log = LogisticRegression(**best_params2)\n",
    "knn = KNeighborsClassifier(**best_params3)\n",
    "rnf = RandomForestClassifier(**best_params4)\n",
    "ext = ExtraTreesClassifier(**best_params5)\n",
    "ada = AdaBoostClassifier(**best_params6)\n",
    "lgb = LGBMClassifier(**best_params7)\n",
    "# svc = SVC(**best_params8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2720, 172)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08822457163689391 0.1593798449612403 vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# vote_list = [('xgb', xgb), ('log', log), ('knn', knn), ('rnf', rnf), ('ext', ext), ('ada', ada), ('svc', svc),('lgb',lgb)]\n",
    "# vote_list = [('xgb', xgb), ('log', log), ('knn', knn), ('rnf', rnf), ('ext', ext), ('ada', ada), ('lgb',lgb)]\n",
    "vote_list = [('log', log), ('ada', ada), ('lgb',lgb)]\n",
    "vote = VotingClassifier(estimators=vote_list, voting='soft')\n",
    "vote.fit(x_sm, y_sm)\n",
    "# vote.fit(x_val, y_val)\n",
    "# y_pre = vote.predict(x_sm)\n",
    "y_pre = vote.predict(x_val)\n",
    "y_pre_2 = vote.predict(x_train)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011363636363636364 0.9952153110047847 vote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EBM_IT_01\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pre = vote.predict(x_val)\n",
    "y_pre_2 = vote.predict(x_train2)\n",
    "f1  = f1_score(y_val, y_pre, average='binary')\n",
    "f1_2  = f1_score(y_train2, y_pre_2, average='binary')\n",
    "print(f1,f1_2,'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.00546448,\n",
       "       0.        , 0.0273224 , 0.01092896, 0.00546448, 0.01092896,\n",
       "       0.00546448, 0.00546448, 0.03278688, 0.04918033, 0.01639344,\n",
       "       0.00546448, 0.03278688, 0.01092896, 0.01092896, 0.        ,\n",
       "       0.        , 0.        , 0.01639344, 0.00546448, 0.01639344,\n",
       "       0.01639344, 0.01092896, 0.00546448, 0.00546448, 0.        ,\n",
       "       0.01639344, 0.02185792, 0.02185792, 0.01092896, 0.01092896,\n",
       "       0.00546448, 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.01639344, 0.        , 0.00546448, 0.        , 0.        ,\n",
       "       0.00546448, 0.        , 0.        , 0.00546448, 0.        ,\n",
       "       0.00546448, 0.        , 0.00546448, 0.        , 0.        ,\n",
       "       0.        , 0.00546448, 0.        , 0.01092896, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00546448, 0.00546448, 0.00546448, 0.        ,\n",
       "       0.00546448, 0.00546448, 0.01092896, 0.        , 0.        ,\n",
       "       0.01092896, 0.        , 0.        , 0.01639344, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01092896, 0.        , 0.00546448, 0.        ,\n",
       "       0.        , 0.        , 0.00546448, 0.01639344, 0.09289618,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02185792, 0.04918033, 0.03278688,\n",
       "       0.02185792, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01092896, 0.02185792, 0.01092896, 0.        ,\n",
       "       0.01092896, 0.00546448, 0.        , 0.        , 0.00546448,\n",
       "       0.        , 0.        , 0.00546448, 0.        , 0.00546448,\n",
       "       0.        , 0.        , 0.00546448, 0.        , 0.02185792,\n",
       "       0.02185792, 0.03825137, 0.03278688, 0.00546448, 0.00546448,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 64, 93, ..., 98, 80, 91])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score , precision_score , recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032520325203252032"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, y_pre, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.00162866])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y, y_pre,pos_label=1, average=None)\n",
    "precision_score(y, y_pre,pos_label=1, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vote.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vote, 'vote.pkl') \n",
    "vote2 = joblib.load('vote.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote2 = joblib.load('vote.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb', RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=nan, n_estimators=100,\n",
       " ...obs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
